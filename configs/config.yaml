# Hyperparameters for MATE-Event-Classifier-DL
# Physics-Informed Deep Learning for MATE TPC Experiment
# Updated: 2024-12 to reflect current architecture

model:
  # Classification task
  num_classes: 2              # Default: binary (3He vs 4He)
                              # Can be changed for multi-class tasks if file_mapping is provided.
  
  # Physics features
  num_physics_params: 4       # Moment of Inertia: I_xx, I_yy, I_xy, Eigen_Ratio
  
  # Architecture (ResNet-18 + Transformer with Physics Token)
  embed_dim: 256              # Token/patch embedding dimension
  num_heads: 8                # Transformer attention heads
  dropout: 0.1                # Dropout rate
  
  # Input format
  in_channels: 2              # Channel 0: Charge, Channel 1: Drift Time (X-coord)

training:
  batch_size: 64              # Batch size for training
  learning_rate: 0.0001       # Initial learning rate (lower for ViT models)
  epochs: 100                 # Maximum number of epochs
  weight_decay: 0.0001        # L2 regularization (AdamW style)
  save_dir: "outputs"         # Directory to save model checkpoints
  scheduler: "cosine"         # "cosine" or "plateau"

data:
  # MATE TPC image format (Y-Z projection)
  img_height: 80              # Y-axis bins
  img_width: 48               # Z-axis bins
  # Note: Images stored as (N, H, W, C) in HDF5, converted to (N, C, H, W) for PyTorch
  
  data_dir: "dataset/HDF5_Form"  # Path to HDF5 data files
  num_workers: 0              # Set to 0 on Windows to avoid multiprocessing issues
  train_split: 0.8            # Fraction of data for training
  
  # Detector physical dimensions (mm)
  detector_y: [-150.0, 150.0]
  detector_z: [0.0, 300.0]
  drift_x: [-100.0, 100.0]

evaluation:
  batch_size: 32              # Batch size for evaluation
  num_vis_samples: 10         # Number of attention visualizations to generate
  output_dir: "outputs"       # Directory for evaluation outputs
